# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025 Beijing QBoson Quantum Technology Co., Ltd
# This file is distributed under the same license as the Kaiwu Pytorch
# Plugin package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2026.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Kaiwu Pytorch Plugin 0.1.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-07 16:34+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: en\n"
"Language-Team: en <LL@li.org>\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:3
msgid "Q-VAE：量子变分自编码器"
msgstr "Q-VAE: Quantum Variational Autoencoder"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:5
msgid ""
"本教程演示如何训练和评估量子变分自编码器（Quantum Variational Autoencoder, Q-VAE）模型。Q-VAE "
"结合了变分自编码器和量子玻尔兹曼机，能够实现更强大的生成和表征学习能力。"
msgstr ""
"This tutorial demonstrates how to train and evaluate a Quantum Variational "
"Autoencoder (Q-VAE) model. Q-VAE combines a variational autoencoder with a "
"quantum Boltzmann machine, enabling more powerful generative and "
"representation-learning capabilities."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:8
msgid "目标"
msgstr "Objectives"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:10
msgid "理解 Q-VAE 的架构和工作原理"
msgstr "Understand the architecture and working principles of Q-VAE"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:11
msgid "在 MNIST 数据集上训练 Q-VAE"
msgstr "Train Q-VAE on the MNIST dataset"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:12
msgid "进行图像重建和生成"
msgstr "Perform image reconstruction and generation"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:13
msgid "使用 Q-VAE 进行表征学习和分类"
msgstr "Use Q-VAE for representation learning and classification"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:14
msgid "使用 t-SNE 可视化潜在空间"
msgstr "Visualize the latent space with t-SNE"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:17
msgid "运行环境"
msgstr "Runtime Environment"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:19
msgid "**示例位置**: ``example/qvae_mnist/``"
msgstr "**Example location**: ``example/qvae_mnist/``"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:21
msgid "``train_qvae.ipynb``: 训练 Q-VAE 模型"
msgstr "``train_qvae.ipynb``: train the Q-VAE model"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:22
msgid "``train_qvae_classifier.ipynb``: 表征学习与分类"
msgstr "``train_qvae_classifier.ipynb``: representation learning & classification"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:24
msgid "**依赖项**:"
msgstr "**Dependencies**:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:31
msgid "1、QVAE 原理概括"
msgstr "1. QVAE Principles at a Glance"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:33
msgid ""
"QVAE（Quantum Variational Autoencoder）是一种将 **量子生成模型** 引入 **变分自编码器 (VAE)** "
"潜空间的生成模型。其核心思想是："
msgstr ""
"QVAE (Quantum Variational Autoencoder) is a generative model that brings "
"**quantum generative models** into the latent space of a **Variational "
"Autoencoder (VAE)**. Its core idea is:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:35
msgid "> **用量子玻尔兹曼机（QBM）替代传统 VAE 中的先验分布，从而构建一个具有量子生成能力的潜变量模型。**"
msgstr ""
"> **Replace the prior distribution in a conventional VAE with a Quantum "
"Boltzmann Machine (QBM), thereby building a latent-variable model endowed "
"with quantum generative power.**"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:38
msgid "模型结构"
msgstr "Model Structure"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:40
msgid "QVAE 包括以下关键组件："
msgstr "QVAE comprises the following key components:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:42
#, python-brace-format
msgid ""
"**编码器（Encoder）** 将输入数据 :math:`\\mathbf{x}` 映射为潜变量的近似后验分布 "
":math:`q_\\phi(\\mathbf{z}|\\mathbf{x})`，通常由神经网络参数化。"
msgstr ""
"**Encoder** maps input data :math:`\\mathbf{x}` to an approximate "
"posterior distribution :math:`q_\\phi(\\mathbf{z}|\\mathbf{x})` over latent "
"variables, typically parameterized by a neural network."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:46
#, python-brace-format
msgid ""
"**先验分布（Prior）** 使用 **量子玻尔兹曼机 (QBM)** 建模潜变量 :math:`\\mathbf{z}` "
"的先验分布。哈密顿量为："
msgstr ""
"**Prior** models the prior distribution over latent variables "
":math:`\\mathbf{z}` with a **Quantum Boltzmann Machine (QBM)**. Its "
"Hamiltonian is:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:49
#, python-brace-format
msgid ""
"\\mathcal{H}_\\theta = \\sum_l \\Gamma_l \\sigma_l^x + \\sum_l h_l "
"\\sigma_l^z + \\sum_{l<m} W_{lm} \\sigma_l^z \\sigma_m^z"
msgstr ""
"\\mathcal{H}_\\theta = \\sum_l \\Gamma_l \\sigma_l^x + \\sum_l h_l "
"\\sigma_l^z + \\sum_{l<m} W_{lm} \\sigma_l^z \\sigma_m^z"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:53
#, python-brace-format
msgid ""
"**解码器（Decoder）** 将潜变量 :math:`\\mathbf{z}` （或其连续松弛变量 "
":math:`\\boldsymbol{\\zeta}` ）映射回数据空间，并使用解码器重建原始数据："
msgstr ""
"**Decoder** maps latent variables :math:`\\mathbf{z}` (or their continuous "
"relaxation :math:`\\boldsymbol{\\zeta}`) back to the data space and "
"reconstructs the original data via:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:56
#, python-brace-format
msgid ""
"p_\\theta(\\mathbf{x} | \\boldsymbol{\\zeta}) \\sim "
"\\text{Bernoulli}(f_\\theta(\\boldsymbol{\\zeta}))"
msgstr ""
"p_\\theta(\\mathbf{x} | \\boldsymbol{\\zeta}) \\sim "
"\\text{Bernoulli}(f_\\theta(\\boldsymbol{\\zeta}))"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:61
msgid "训练目标：Q-ELBO"
msgstr "Training Objective: Q-ELBO"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:63
msgid "QVAE 使用一个 **量子下界 (Q-ELBO)** 来近似最大化对数似然："
msgstr ""
"QVAE maximizes an approximate log-likelihood via a **Quantum Evidence Lower "
"BOund (Q-ELBO)**:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:65
msgid ""
"\\mathcal{L}_{\\text{Q-ELBO}} = "
"\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} [\\log "
"p_\\theta(\\mathbf{x} | \\boldsymbol{\\zeta})] - "
"\\tilde{H}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}))"
msgstr ""
"\\mathcal{L}_{\\text{Q-ELBO}} = "
"\\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} [\\log "
"p_\\theta(\\mathbf{x} | \\boldsymbol{\\zeta})] - "
"\\tilde{H}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}))"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:70
msgid "QBM 采样与训练"
msgstr "QBM Sampling & Training"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:72
#, python-brace-format
msgid ""
"**正相（positive phase）**：从编码器采样 :math:`\\mathbf{z} \\sim "
"q_\\phi(\\mathbf{z}|\\mathbf{x})`"
msgstr ""
"**Positive phase**: sample :math:`\\mathbf{z} \\sim "
"q_\\phi(\\mathbf{z}|\\mathbf{x})` from the encoder"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:73
#, python-brace-format
msgid ""
"**负相（negative phase）**：从 QBM 中采样 :math:`\\mathbf{z} \\sim "
"p_\\theta(\\mathbf{z})`，使用 **蒙特卡洛方法** 或 **量子退火器**"
msgstr ""
"**Negative phase**: sample :math:`\\mathbf{z} \\sim p_\\theta(\\mathbf{z})` "
"from the QBM using **Monte-Carlo methods** or a **quantum annealer**"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:75
msgid "把能量作为目标函数，objective 的梯度即为基于正相和负相采样计算的梯度。"
msgstr ""
"Energy serves as the objective; gradients are computed from positive- and "
"negative-phase samples."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:79
msgid "2. 模型架构"
msgstr "2. Model Architecture"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:81
msgid "定义了用于自编码器架构的 ``Encoder`` 和 ``Decoder`` 两个模块，均继承自 ``nn.Module``。"
msgstr ""
"The ``Encoder`` and ``Decoder`` modules for the auto-encoder architecture "
"are defined, both inheriting from ``nn.Module``."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:83
msgid ""
"两者结构对称：包含一个全连接层、层归一化（LayerNorm）和双曲正切激活函数，并支持通过 L2 权重衰减进行正则化。 "
"编码器将高维输入映射到低维潜在空间，而解码器尝试从潜在表示重构原始输入。 每个模块提供 ``get_weight_decay`` "
"方法，用于在训练损失中显式加入权重正则项，以提升模型泛化能力并防止过拟合。"
msgstr ""
"They are structurally symmetric: each contains a fully-connected layer, "
"LayerNorm, and a tanh activation, and supports L2 weight-decay "
"regularization. The encoder maps high-dimensional inputs to a low-dimensional "
"latent space, while the decoder attempts to reconstruct the original input "
"from the latent representation. Each module exposes a "
"``get_weight_decay`` method to explicitly add weight regularization to the "
"training loss, improving generalization and mitigating over-fitting."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:88
msgid "2.1 编码器"
msgstr "2.1 Encoder"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:94
msgid "2.2 解码器"
msgstr "2.2 Decoder"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:100
msgid "2.3 Q-VAE 完整模型"
msgstr "2.3 Complete Q-VAE Model"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:102
msgid "参考模块手册中的QVAE类。"
msgstr "Refer to the QVAE class in the module manual."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:105
msgid "3. 数据准备"
msgstr "3. Data Preparation"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:107
msgid "该函数封装了 MNIST 数据集的加载与预处理流程，返回训练和测试用的 ``DataLoader``。"
msgstr ""
"This function encapsulates loading and pre-processing of the MNIST dataset, "
"returning training and test ``DataLoader`` objects."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:109
msgid ""
"数据通过 ``ToTensor`` 转换为张量，并利用自定义的 ``flatten_tensor`` 将 28×28 图像展平为 784 "
"维向量，适配全连接网络输入。 训练加载器启用打乱（shuffle），而测试加载器保持顺序以确保评估一致性。"
msgstr ""
"Data are converted to tensors via ``ToTensor`` and 28×28 images are "
"flattened into 784-D vectors by a custom ``flatten_tensor`` to suit "
"fully-connected inputs. The training loader shuffles data, while the test "
"loader keeps order for consistent evaluation."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:173
msgid "4. 模型训练"
msgstr "4. Model Training"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:175
msgid ""
"该函数实现了量子变分自编码器（Q-VAE）在 MNIST 数据集上的完整训练流程。 "
"模型结合了经典神经网络编码器/解码器与受限玻尔兹曼机（RBM），通过最小化带权重衰减的负 ELBO 损失进行优化，并引入 KL "
"散度控制潜在分布与先验的对齐程度。 训练过程中记录各项损失指标并定期保存至文件。"
msgstr ""
"This function implements the complete training pipeline of a Quantum "
"Variational Autoencoder (Q-VAE) on MNIST. The model combines classical "
"neural encoder/decoder networks with a Restricted Boltzmann Machine (RBM), "
"optimized by minimizing the negative ELBO loss with weight decay and a KL "
"divergence term that aligns the latent distribution with the prior. All loss "
"components are logged and periodically saved to disk."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:183
msgid "5. 可视化与评估"
msgstr "5. Visualization & Evaluation"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:184
msgid ""
"本节提供两类关键可视化工具： 一是通过 ``plot_training_curves`` 绘制训练/验证损失与准确率曲线，用于监控模型收敛情况； "
"二是利用 ``t_SNE`` 对 QVAE 模型提取的潜在表示进行降维可视化，揭示不同类别在隐空间中的分布结构。 "
"两者均支持自动保存高分辨率图像，并可灵活控制是否实时显示，便于实验分析、结果记录。"
msgstr ""
"This section supplies two key visualization tools: (1) "
"``plot_training_curves`` for monitoring convergence by plotting training/"
"validation loss and accuracy curves; (2) ``t_SNE`` for dimensionality "
"reduction and visualization of latent representations extracted by the QVAE, "
"revealing how different classes are distributed in latent space. Both "
"support automatic saving of high-resolution images and optional real-time "
"display for convenient experiment tracking and reporting."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:190
msgid "5.1 训练过程可视化"
msgstr "5.1 Training-Process Visualization"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:196
msgid "5.3 潜在空间可视化"
msgstr "5.3 Latent-Space Visualization"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:202
msgid "6. 表征学习与分类"
msgstr "6. Representation Learning & Classification"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:204
msgid "Q-VAE 学到的表征可用于下游分类任务："
msgstr "Representations learned by Q-VAE can be used for downstream classification:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:206
msgid ""
"该函数 ``train_mlp_classifier`` 用于训练一个多层感知机(MLP)分类器，输入特征是通过QVAE模型提取的数据表征。 "
"它首先将数据集划分为训练集和验证集，并初始化一个MLP模型、优化器和损失函数。 在每个训练周期，模型参数根据训练集更新，并在验证集上评估性能。"
msgstr ""
"The function ``train_mlp_classifier`` trains a multi-layer perceptron (MLP) "
"classifier whose input features are the representations extracted by the "
"QVAE. It first splits the dataset into training and validation sets, then "
"initializes an MLP model, optimizer, and loss function. During each epoch "
"parameters are updated on the training set and performance is evaluated on "
"the validation set."

#: ../../source/getting_started/tutorials/qvae_mnist.rst:216
msgid "7. 科研应用：QBM-VAE"
msgstr "7. Research Applications: QBM-VAE"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:218
msgid "Q-VAE 的进阶版本 QBM-VAE 在科研中展示了重要价值："
msgstr ""
"The advanced Q-VAE variant QBM-VAE has demonstrated significant value in "
"research:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:220
msgid "**单细胞转录组学分析**："
msgstr "**Single-cell transcriptomics analysis**:"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:222
msgid "显著提升聚类精度"
msgstr "Substantially improves clustering accuracy"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:223
msgid "检测传统方法无法辨识的新型细胞亚型"
msgstr "Detects novel cell sub-types invisible to conventional methods"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:224
msgid "为靶点发现提供新线索"
msgstr "Provides new leads for target discovery"

#: ../../source/getting_started/tutorials/qvae_mnist.rst:226
msgid ""
"**相关论文**：`Quantum-Boosted High-Fidelity Deep Learning "
"<https://arxiv.org/pdf/2508.11190 >`_"
msgstr ""
"**Related paper**: `Quantum-Boosted High-Fidelity Deep Learning "
"<https://arxiv.org/pdf/2508.11190>`_"